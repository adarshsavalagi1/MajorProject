import ollama

from utils.textbook import TextbookPrompt



class Engine:
    def __init__(self):
        """
        Initialize the Engine and connect to the Ollama client.
        """
        try:
            self.ollama = ollama.Client()  # Instantiate the Ollama client
        except Exception as e:
            print(f"Failed to initialize Ollama client: {e}")
            self.ollama = None

    def is_ready(self) -> bool:
        """
        Check if the engine is ready to process requests.
        Returns True if Ollama client is initialized, False otherwise.
        """
        return self.ollama is not None

    def get_response(self, ) -> str:
        """
        Generate a response for the given prompt using the Ollama client.
        
        Args:
            prompt (TextbookPrompt): The prompt to generate a response for.

        Returns:
            str: The response generated by the model.
        """
        if not self.is_ready():
            return "Engine is not ready. Please check the configuration."

        try:
            return "hi"
        except Exception as e:
            return f"Error generating response: {e}"

    def close(self):
        """
        Close the Ollama client connection.
        """
        if self.ollama:
            self.ollama.close()

# Example usage
if __name__ == "__main__":
    engine = Engine()
    prompt = TextbookPrompt("Explain Newton's laws of motion.", metadata={"subject": "Physics", "level": "High School"})

    if engine.is_ready():
        print("Engine is ready.")
        response = engine.get_response(prompt)
        print("Response:", response)
    else:
        print("Engine is not ready.")
